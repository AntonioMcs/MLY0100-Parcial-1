{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3_DecisionTree_Diabetes\n",
    "\n",
    "**Proyecto:** MLY0100 ‚Äî Predicci√≥n de Riesgo de Diabetes  \n",
    "**Modelo:** √Årbol de Decisi√≥n (Decision Tree Classifier)  \n",
    "**Autor:** Antonio Sep√∫lveda  \n",
    "**Fecha:** 2025"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conexi√≥n con Kedro y carga del dataset\n",
    "\n",
    "En este notebook se implementa un modelo de **√Årbol de Decisi√≥n** para clasificar pacientes seg√∫n la variable objetivo **Outcome**:\n",
    "- `0` ‚Üí No Diabetes  \n",
    "- `1` ‚Üí Diabetes\n",
    "\n",
    "Se utilizar√°n los datos limpios generados por el pipeline de Kedro (`diabetes_cleaned`)."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kedro.ipython\n",
    "%reload_kedro\n",
    "\n",
    "# Listar datasets disponibles en el cat√°logo\n",
    "catalog.list()"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset limpio desde Kedro\n",
    "df_diabetes = catalog.load('diabetes_cleaned')\n",
    "\n",
    "print(df_diabetes.shape)\n",
    "df_diabetes.head()"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Distribuci√≥n de la variable objetivo (Outcome)\n",
    "\n",
    "Revisamos el equilibrio de clases para entender si el problema est√° balanceado o desbalanceado."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='Outcome', data=df_diabetes)\n",
    "plt.title('Distribuci√≥n de la variable Outcome')\n",
    "plt.xlabel('Outcome (0 = No Diabetes, 1 = Diabetes)')\n",
    "plt.ylabel('Cantidad de pacientes')\n",
    "plt.show()\n",
    "\n",
    "df_diabetes['Outcome'].value_counts(normalize=True)"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importaciones para modelado y m√©tricas\n",
    "\n",
    "Se importan las librer√≠as necesarias para entrenamiento, evaluaci√≥n y visualizaci√≥n del √Årbol de Decisi√≥n."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecci√≥n de caracter√≠sticas\n",
    "\n",
    "Utilizaremos todas las variables num√©ricas del dataset como caracter√≠sticas (`X`) y la variable **Outcome** como objetivo (`y`)."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = todas las columnas excepto Outcome\n",
    "X = df_diabetes.drop('Outcome', axis=1)\n",
    "y = df_diabetes['Outcome']\n",
    "\n",
    "print('Dimensiones de X:', X.shape)\n",
    "print('Dimensiones de y:', y.shape)\n",
    "X.head()"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Divisi√≥n de datos en entrenamiento y prueba\n",
    "\n",
    "Se divide el conjunto en:\n",
    "- 80% para **entrenamiento**\n",
    "- 20% para **prueba**\n",
    "\n",
    "Se utiliza `stratify=y` para conservar la proporci√≥n de clases."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test :', X_test.shape)"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del modelo √Årbol de Decisi√≥n (versi√≥n base)\n",
    "\n",
    "Primero se entrena un modelo base con hiperpar√°metros simples para entender el comportamiento inicial."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_base = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=4,      # profundidad controlada para evitar sobreajuste\n",
    "    criterion='gini'  # criterio est√°ndar\n",
    ")\n",
    "\n",
    "dt_base.fit(X_train, y_train)\n",
    "\n",
    "y_pred_base = dt_base.predict(X_test)\n",
    "y_proba_base = dt_base.predict_proba(X_test)[:, 1]"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. M√©tricas de evaluaci√≥n ‚Äî Modelo base\n",
    "\n",
    "Se calculan las m√©tricas principales:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall (Sensitivity)  \n",
    "- F1-score"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_base = accuracy_score(y_test, y_pred_base)\n",
    "prec_base = precision_score(y_test, y_pred_base, zero_division=0)\n",
    "rec_base = recall_score(y_test, y_pred_base, zero_division=0)\n",
    "f1_base = f1_score(y_test, y_pred_base, zero_division=0)\n",
    "\n",
    "print('üîç M√©tricas modelo base (√Årbol de Decisi√≥n):\\n')\n",
    "print(f\"Accuracy : {acc_base:.4f}\")\n",
    "print(f\"Precision: {prec_base:.4f}\")\n",
    "print(f\"Recall   : {rec_base:.4f}\")\n",
    "print(f\"F1-score : {f1_base:.4f}\\n\")\n",
    "\n",
    "print('üìã Classification Report:\\n')\n",
    "print(classification_report(y_test, y_pred_base, zero_division=0))"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Matriz de confusi√≥n ‚Äî Modelo base\n",
    "\n",
    "Se visualiza la matriz de confusi√≥n para analizar los aciertos y errores del modelo."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_base = confusion_matrix(y_test, y_pred_base)\n",
    "cm_base"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_base, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusi√≥n ‚Äî √Årbol de Decisi√≥n (Base)')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Sensitivity y Specificity ‚Äî Modelo base\n",
    "\n",
    "- **Sensitivity (Recall de la clase positiva)** = TP / (TP + FN)  \n",
    "- **Specificity** = TN / (TN + FP)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm_base.ravel()\n",
    "\n",
    "sensitivity_base = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity_base = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print(f\"Sensitivity (Recall, clase 1): {sensitivity_base:.4f}\")\n",
    "print(f\"Specificity (clase 0)        : {specificity_base:.4f}\")"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Curva ROC y Curva Precisi√≥n-Recall ‚Äî Modelo base\n",
    "\n",
    "Se calculan y visualizan las curvas **ROC** y **Precisi√≥n-Recall** para evaluar el rendimiento del modelo en t√©rminos de umbrales de decisi√≥n."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Curva ROC ---\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test, y_proba_base)\n",
    "roc_auc_base = auc(fpr_base, tpr_base)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_base, tpr_base, color='darkorange', lw=2,\n",
    "         label=f'ROC curve (AUC = {roc_auc_base:.2f})')\n",
    "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC ‚Äî √Årbol de Decisi√≥n (Base)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Curva Precisi√≥n-Recall ---\n",
    "precision_base, recall_base, _ = precision_recall_curve(y_test, y_proba_base)\n",
    "ap_base = average_precision_score(y_test, y_proba_base)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recall_base, precision_base, color='blue', lw=2,\n",
    "         label=f'PR curve (AP = {ap_base:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall ‚Äî √Årbol de Decisi√≥n (Base)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Importancia de caracter√≠sticas ‚Äî Modelo base\n",
    "\n",
    "Los √Årboles de Decisi√≥n permiten interpretar la importancia relativa de cada variable para la clasificaci√≥n."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(dt_base.feature_importances_, index=X.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=feature_importances.values, y=feature_importances.index)\n",
    "plt.title('Importancia de caracter√≠sticas ‚Äî √Årbol de Decisi√≥n (Base)')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "feature_importances"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizaci√≥n del √Årbol de Decisi√≥n (opcional)\n",
    "\n",
    "A continuaci√≥n se visualiza el √°rbol entrenado (cuando la profundidad no es muy grande). Esto permite interpretar reglas de decisi√≥n."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "large_output_optional"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plot_tree(\n",
    "    dt_base,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['No Diabetes', 'Diabetes'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=3  # limitar profundidad en la visualizaci√≥n\n",
    ")\n",
    "plt.title('√Årbol de Decisi√≥n ‚Äî Visualizaci√≥n Parcial (max_depth=3)')\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. B√∫squeda de hiperpar√°metros con GridSearchCV\n",
    "\n",
    "Se realiza una b√∫squeda de hiperpar√°metros para mejorar el rendimiento del modelo utilizando **GridSearchCV**.\n",
    "\n",
    "Hiperpar√°metros a explorar:\n",
    "- `max_depth`\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `criterion`"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Mejores par√°metros:', grid_search.best_params_)\n",
    "print('Mejor accuracy (CV):', round(grid_search.best_score_, 4))"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluaci√≥n del mejor modelo (GridSearchCV)\n",
    "\n",
    "Se eval√∫a el mejor √°rbol encontrado por GridSearchCV sobre el conjunto de prueba."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_dt.predict(X_test)\n",
    "y_proba_best = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_best = accuracy_score(y_test, y_pred_best)\n",
    "prec_best = precision_score(y_test, y_pred_best, zero_division=0)\n",
    "rec_best = recall_score(y_test, y_pred_best, zero_division=0)\n",
    "f1_best = f1_score(y_test, y_pred_best, zero_division=0)\n",
    "\n",
    "print('üîç M√©tricas mejor modelo (GridSearchCV ‚Äî √Årbol de Decisi√≥n):\\n')\n",
    "print(f\"Accuracy : {acc_best:.4f}\")\n",
    "print(f\"Precision: {prec_best:.4f}\")\n",
    "print(f\"Recall   : {rec_best:.4f}\")\n",
    "print(f\"F1-score : {f1_best:.4f}\\n\")\n",
    "\n",
    "print('üìã Classification Report (Best Model):\\n')\n",
    "print(classification_report(y_test, y_pred_best, zero_division=0))"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Matriz de confusi√≥n ‚Äî Mejor modelo\n"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Matriz de confusi√≥n ‚Äî √Årbol de Decisi√≥n (Best Model)')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "cm_best"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Sensitivity y Specificity ‚Äî Mejor modelo\n"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_b, fp_b, fn_b, tp_b = cm_best.ravel()\n",
    "\n",
    "sensitivity_best = tp_b / (tp_b + fn_b) if (tp_b + fn_b) > 0 else 0\n",
    "specificity_best = tn_b / (tn_b + fp_b) if (tn_b + fp_b) > 0 else 0\n",
    "\n",
    "print(f\"Sensitivity (Best Model): {sensitivity_best:.4f}\")\n",
    "print(f\"Specificity (Best Model): {specificity_best:.4f}\")"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Curva ROC y Curva PR ‚Äî Mejor modelo\n"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Curva ROC (Best Model) ---\n",
    "fpr_b, tpr_b, _ = roc_curve(y_test, y_proba_best)\n",
    "roc_auc_b = auc(fpr_b, tpr_b)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_b, tpr_b, color='darkorange', lw=2,\n",
    "         label=f'ROC curve (AUC = {roc_auc_b:.2f})')\n",
    "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC ‚Äî √Årbol de Decisi√≥n (Best Model)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Curva Precision-Recall (Best Model) ---\n",
    "precision_b, recall_b, _ = precision_recall_curve(y_test, y_proba_best)\n",
    "ap_b = average_precision_score(y_test, y_proba_best)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recall_b, precision_b, color='blue', lw=2,\n",
    "         label=f'PR curve (AP = {ap_b:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall ‚Äî √Årbol de Decisi√≥n (Best Model)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }

 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
